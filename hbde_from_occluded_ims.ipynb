{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Body Dimension Estimation (HBDE) from occluded images\n",
    "\n",
    "### Authors: M. Beiwinkler, M. KrimpelstÃ¤tter, I. Viertola and T. Wulz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from skimage.io import imread\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, MSELoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout, Flatten\n",
    "from torch.optim import Adam, SGD\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATASET_PATH = os.path.join(os.getcwd(), \"dataset\")\n",
    "TRAIN_TEST_PATH = os.path.join(DATASET_PATH, os.path.join(\"train_test\", \"train_test_split.json\"))\n",
    "IMS_PATH = os.path.join(DATASET_PATH, os.path.join(\"synthetic_images\", \"200x200\"))\n",
    "ANNOS_PATH = os.path.join(DATASET_PATH, \"annotations\")\n",
    "FULL_DATA_NP_ARRAY_PATH = os.path.join(os.getcwd(), \"im_data.npy\")\n",
    "FULL_DATA_WITH_OCCLUSIONS_NP_ARRAY_PATH = os.path.join(os.getcwd(), \"im_data_with_occlusions.npy\")\n",
    "CHOSEN_ANNOS_NP_ARRAY_PATH = os.path.join(os.getcwd(), \"im_annos.npy\")\n",
    "\n",
    "if not os.path.exists(IMS_PATH):\n",
    "    print(\"Dataset does not exist {}\".format(DATASET_PATH))\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " class ImageDataset(Dataset):\n",
    "    def __init__(self, with_occlusions=False, transform=None, target_transform=None):\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        if with_occlusions and os.path.exists(FULL_DATA_WITH_OCCLUSIONS_NP_ARRAY_PATH):\n",
    "            # Load occluded images from file\n",
    "            self.im_data = np.load(FULL_DATA_WITH_OCCLUSIONS_NP_ARRAY_PATH)\n",
    "            if not self.im_data.shape == (12000, 200, 200):\n",
    "                print(\"Problems with occluded image data.\")\n",
    "                exit()\n",
    "        else:\n",
    "            # Load data from file or from the dataset\n",
    "            if os.path.exists(FULL_DATA_NP_ARRAY_PATH):\n",
    "                self.im_data = np.load(FULL_DATA_NP_ARRAY_PATH)\n",
    "                self.im_annos = np.load(CHOSEN_ANNOS_NP_ARRAY_PATH)\n",
    "            else:\n",
    "                im_data = []\n",
    "                im_annos = []\n",
    "                for anno_fn in sorted(glob.glob(os.path.join(ANNOS_PATH, os.path.join(\"*\", \"*.json\")))):\n",
    "                    f = open(anno_fn, \"r\")\n",
    "                    annotations = json.load(f)\n",
    "                    im_annos.append([annotations['human_dimensions']['height'], annotations['human_dimensions']['shoulder_width'],\n",
    "                                     annotations['human_dimensions']['left_arm_length'], annotations['human_dimensions']['right_arm_length'],\n",
    "                                     annotations['human_dimensions']['pelvis_circumference'], annotations['human_dimensions']['chest_circumference']])\n",
    "                for img_fn in sorted(glob.glob(os.path.join(IMS_PATH, os.path.join(\"**\", \"*.png\")), recursive=True)):\n",
    "                    img = imread(img_fn)\n",
    "                    img = img.astype('float32')\n",
    "                    img /= 255.0\n",
    "                    im_data.append(img)\n",
    "\n",
    "                self.im_data = np.array(im_data)\n",
    "                self.im_annos = np.array(im_annos)\n",
    "                with open(FULL_DATA_NP_ARRAY_PATH, \"wb+\") as f:\n",
    "                    np.save(f, self.im_data)\n",
    "                    f.close()\n",
    "                with open(CHOSEN_ANNOS_NP_ARRAY_PATH, \"wb+\") as f:\n",
    "                    np.save(f, self.im_annos)\n",
    "                    f.close()\n",
    "\n",
    "            if not self.im_data.shape == (12000, 200, 200):\n",
    "                print(\"Problems with image data.\")\n",
    "                exit()\n",
    "            if not self.im_annos.shape == (6000, 6):\n",
    "                print(\"Problems with image data.\")\n",
    "                exit()\n",
    "                    \n",
    "            if with_occlusions:\n",
    "                # Generate occluded images\n",
    "                # Seed pseudo-random number generator for reproducibility\n",
    "                random.seed(a=\"HBDE from occluded images\", version=2)\n",
    "\n",
    "                # Add rectangles to images\n",
    "                im_data_occl = []\n",
    "                for img_np in self.im_data:\n",
    "                    # Determine position, length and width of occluding rectangle\n",
    "                    upper_left_x = random.randrange(0, 200)\n",
    "                    upper_left_y = random.randrange(0, 200)\n",
    "                    lower_right_x = upper_left_x + random.randrange(0, 50)\n",
    "                    lower_right_y = upper_left_y + random.randrange(0, 50)\n",
    "\n",
    "                    # Convert from NumPy array to instance of Pillow Image class\n",
    "                    img = Image.fromarray(img_np)\n",
    "\n",
    "                    # Draw rectangles\n",
    "                    draw = ImageDraw.Draw(img)\n",
    "                    draw.rectangle((upper_left_x, upper_left_y, lower_right_x, lower_right_y), fill=\"black\")\n",
    "\n",
    "                    # Add manipulated image to array of occluded images\n",
    "                    im_data_occl.append(np.asarray(img))\n",
    "        \n",
    "                self.im_data = np.array(im_data_occl)\n",
    "                with open(FULL_DATA_WITH_OCCLUSIONS_NP_ARRAY_PATH, \"wb+\") as f:\n",
    "                    np.save(f, self.im_data)\n",
    "                    f.close()\n",
    "                if not self.im_data.shape == (12000, 200, 200):\n",
    "                    print(\"Problems with occluded image data.\")\n",
    "                    exit()\n",
    "        # Review data\n",
    "        #plt.figure(figsize=(15, 15))\n",
    "        #plt.subplot(221), plt.imshow(self.im_data[0], cmap='gray'), plt.title(\"Female, pose 0\")\n",
    "        #plt.subplot(222), plt.imshow(self.im_data[3001], cmap='gray'), plt.title(\"Male, pose 0\")\n",
    "        #plt.subplot(223), plt.imshow(self.im_data[6001], cmap='gray'), plt.title(\"Female, pose 1\")\n",
    "        #plt.subplot(224), plt.imshow(self.im_data[9001], cmap='gray'), plt.title(\"Male, pose 1\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.im_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.im_data[idx]\n",
    "        #print(f\"{idx}, {len(self.im_annos)}, {idx % len(self.im_annos)}\")\n",
    "        annotations = np.float32(self.im_annos[idx % len(self.im_annos)])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            annotations = self.target_transform(annotations)\n",
    "        #print(f\"{image.dtype} {annotations.dtype}\")\n",
    "        return image, annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the CNN\n",
    "Selected features (6): \n",
    "- height\n",
    "- shoulder width\n",
    "- left arm length\n",
    "- right arm length\n",
    "- pelvis circumference\n",
    "- chest circumference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): MaxPool2d(kernel_size=5, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): MaxPool2d(kernel_size=5, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Flatten(start_dim=1, end_dim=-1)\n",
      "    (9): Linear(in_features=30976, out_features=30976, bias=True)\n",
      "    (10): ReLU(inplace=True)\n",
      "    (11): Linear(in_features=30976, out_features=6, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "feature_amnt = 6\n",
    "\n",
    "class CNN(Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.layers = Sequential(\n",
    "            Conv2d(in_channels=1, out_channels=feature_amnt, kernel_size=5),\n",
    "            ReLU(inplace=True),\n",
    "            BatchNorm2d(num_features=feature_amnt),\n",
    "            MaxPool2d(kernel_size=5, stride=2),\n",
    "            # Second convolutional layer\n",
    "            Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n",
    "            ReLU(inplace=True),  # Are these irrelevant?\n",
    "            BatchNorm2d(num_features=16),  # Are these irrelevant?\n",
    "            MaxPool2d(kernel_size=5, stride=2),\n",
    "            Flatten(),\n",
    "            Linear(in_features=30976, out_features=30976),  # Drop the out feature amount here?\n",
    "            ReLU(inplace=True),\n",
    "            Linear(in_features=30976, out_features=feature_amnt)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "model = CNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "training_data = ImageDataset(transform=ToTensor())\n",
    "test_data = ImageDataset(with_occlusions=True, transform=ToTensor(), target_transform=ToTensor())\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=100)\n",
    "test_dataloader = DataLoader(test_data, batch_size=100)\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "# optimizer\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "# the loss function\n",
    "criterion = MSELoss()\n",
    "\n",
    "\n",
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, criterion, optimizer)\n",
    "    test_loop(test_dataloader, model, criterion)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4fdc2f73bf5d480b4cf34a598d9b45a8492d840372cfa5913d0a708f31ebf008"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
